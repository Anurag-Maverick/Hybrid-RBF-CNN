{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/heartbeat/ptbdb_abnormal.csv\n/kaggle/input/heartbeat/ptbdb_normal.csv\n/kaggle/input/heartbeat/mitbih_test.csv\n/kaggle/input/heartbeat/mitbih_train.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimport pywt\nimport scipy\nfrom skimage.restoration import denoise_wavelet\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.cluster import KMeans\nfrom tensorflow.keras.layers import Layer, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.initializers import RandomUniform, Initializer, Constant\nfrom tensorflow.keras.models import Sequential\nimport tensorflow.keras.backend as K\n\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n\nfrom keras.utils.np_utils import to_categorical \n\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.callbacks import LearningRateScheduler, ReduceLROnPlateau","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv',header=None)\ntest_df=pd.read_csv('/kaggle/input/heartbeat/mitbih_test.csv',header=None)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = np.array(train_df[train_df.columns[0:-1]], dtype=np.float32)\ntrain_y = np.array(train_df[train_df.columns[-1]], dtype=np.float32)\n\ntest_x = np.array(test_df[test_df.columns[0:-1]], dtype=np.float32)\ntest_y = np.array(test_df[test_df.columns[-1]], dtype=np.float32)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))\ncind=c.index.to_numpy()\ncind","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"array([56376, 73329, 78752, 80812, 82784])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(train_x)):\n    train_x[i] =  denoise_wavelet(train_x[i] ,method='BayesShrink', mode='soft',\n                           rescale_sigma=True, wavelet='sym8', wavelet_levels=3)\n\nfor i in range(len(test_x)):\n    test_x[i] =  denoise_wavelet(test_x[i] ,method='BayesShrink', mode='soft',\n                           rescale_sigma=True, wavelet='sym8', wavelet_levels=3)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def wpd(x):\n\n    Xfeatures=np.zeros((len(x),8,29))\n\n    for i in range(len(x)):\n        wpack=pywt.WaveletPacket(data=x[i], wavelet='db4')\n        Xfeatures[i]=np.vstack((wpack['aaa'].data,wpack['add'].data,wpack['dad'].data,wpack['dda'].data,\n                                wpack['aad'].data,wpack['daa'].data,wpack['ada'].data,wpack['ddd'].data))\n    \n    return Xfeatures","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xfeatures=wpd(train_x)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scaling(x):\n    sc=MinMaxScaler([0,1])\n    x=x.reshape(len(x),len(x[0]),len(x[0][0]),1)\n    scaled=np.zeros((len(x),len(x[0]),len(x[0][0]),1))\n    #x=x.reshape(len(x),len(x[0]),len(x[0][0]))\n    \n    for i in range(len(x)):\n        for j in range(8):\n            sc.fit(x[i][j])\n            scaled[i][j]=sc.transform(x[i][j])\n            \n    return scaled","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xfeat_scaled = scaling(Xfeatures)\nXfeat_scaled = Xfeat_scaled.reshape(-1,8,29)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def wps(x):\n    Xps= np.zeros((len(x),len(x[0]),len(x[0][0])))\n    \n    for i in range(len(x)):\n        Xps[i]=np.square(np.abs(x[i]))        \n        \n    return Xps","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xscaled_power_spectrum = wps(Xfeat_scaled)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xapprox = Xscaled_power_spectrum[:,0,:]\nX_train, X_test, y_train, y_test = train_test_split(Xapprox, train_y, test_size=0.25, random_state=42, stratify=train_y)\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=5)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=5) \n\nprint(\"Number transactions X_train dataset: \", X_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions X_test dataset: \", X_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","execution_count":13,"outputs":[{"output_type":"stream","text":"Number transactions X_train dataset:  (65665, 29)\nNumber transactions y_train dataset:  (65665, 5)\nNumber transactions X_test dataset:  (21889, 29)\nNumber transactions y_test dataset:  (21889, 5)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class InitCentersKMeans(Initializer):\n    \"\"\" Initializer for initialization of centers of RBF network\n        by clustering the given data set.\n    # Arguments\n        X: matrix, dataset\n    \"\"\"\n\n    def __init__(self, X, max_iter=100):\n        self.X = X\n        self.max_iter = max_iter\n        super().__init__()\n\n    def __call__(self, shape, dtype=None):\n        #assert shape[0:] == self.X.shape[1:]\n\n        n_centers = shape[0]\n        km = KMeans(n_clusters=n_centers, max_iter=self.max_iter, verbose=0, init='k-means++')\n        km.fit(self.X)\n        return km.cluster_centers_","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RBFLayer(Layer):\n\n    def __init__(self, output_dim, initializer=None, betas=2.0, **kwargs):\n\n        self.output_dim = output_dim\n\n        # betas is either initializer object or float\n        if isinstance(betas, Initializer):\n            self.betas_initializer = betas\n        else:\n            self.betas_initializer = Constant(value=betas)\n\n        self.initializer = initializer if initializer else RandomUniform(\n            0.0, 1.0)\n\n        super().__init__(**kwargs)\n\n    def build(self, input_shape):\n\n        self.centers = self.add_weight(name='centers',\n                                       shape=(self.output_dim, input_shape[1]),\n                                       initializer=self.initializer,\n                                       trainable=True)\n        self.betas = self.add_weight(name='betas',\n                                     shape=(self.output_dim,),\n                                     initializer=self.betas_initializer,\n                                     # initializer='ones',\n                                     trainable=True)\n\n        super().build(input_shape)\n\n    def call(self, x):\n\n        C = tf.expand_dims(self.centers, -1)  # inserts a dimension of 1\n        H = tf.transpose(C-tf.transpose(x))  # matrix of differences\n        return tf.exp(-self.betas * tf.math.reduce_sum(H**2, axis=1))\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.output_dim)\n\n    def get_config(self):\n        # have to define get_config to be able to use model_from_json\n        config = {\n            'output_dim': self.output_dim\n        }\n        base_config = super().get_config()\n        return dict(list(base_config.items()) + list(config.items()))","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rbflayer = RBFLayer(232,\n                    initializer=InitCentersKMeans(X_train),\n                    betas=2.0,\n                    input_shape=(29,))\n#-----Input layer------#\n\ninputs=tf.keras.layers.Input(shape=(29,))\n\n#-----RBF layer------#\n\nx1=rbflayer(inputs)\nx=Dense(5, activation='softmax', name='output')(x1)\n\noutputs=x\n\nmodel1=tf.keras.Model(inputs=inputs, outputs=outputs)\nmodel1.summary()","execution_count":16,"outputs":[{"output_type":"stream","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 29)]              0         \n_________________________________________________________________\nrbf_layer (RBFLayer)         (None, 232)               6960      \n_________________________________________________________________\noutput (Dense)               (None, 5)                 1165      \n=================================================================\nTotal params: 8,125\nTrainable params: 8,125\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.compile(loss=tf.keras.losses.categorical_crossentropy,\n                  optimizer='Adam',\n                 metrics=['accuracy'])\n\nannealer = LearningRateScheduler(lambda x: 1e-2 * 0.9 ** x)\n\n\nhistory=model1.fit(X_train, y_train,\n              batch_size=64,\n              epochs=100,\n                  steps_per_epoch=len(X_train)//64,\n              validation_data=(X_test,y_test),\n                  callbacks=[annealer])","execution_count":17,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n1026/1026 [==============================] - 5s 4ms/step - loss: 0.3605 - accuracy: 0.9027 - val_loss: 0.1990 - val_accuracy: 0.9451\nEpoch 2/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.2013 - accuracy: 0.9460 - val_loss: 0.1773 - val_accuracy: 0.9549\nEpoch 3/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1914 - accuracy: 0.9489 - val_loss: 0.1645 - val_accuracy: 0.9570\nEpoch 4/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1703 - accuracy: 0.9546 - val_loss: 0.1578 - val_accuracy: 0.9591\nEpoch 5/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1614 - accuracy: 0.9564 - val_loss: 0.1819 - val_accuracy: 0.9497\nEpoch 6/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1595 - accuracy: 0.9574 - val_loss: 0.1511 - val_accuracy: 0.9609\nEpoch 7/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1516 - accuracy: 0.9590 - val_loss: 0.1450 - val_accuracy: 0.9610\nEpoch 8/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1482 - accuracy: 0.9592 - val_loss: 0.1468 - val_accuracy: 0.9608\nEpoch 9/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1523 - accuracy: 0.9592 - val_loss: 0.1408 - val_accuracy: 0.9614\nEpoch 10/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1411 - accuracy: 0.9624 - val_loss: 0.1350 - val_accuracy: 0.9639\nEpoch 11/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1401 - accuracy: 0.9624 - val_loss: 0.1419 - val_accuracy: 0.9625\nEpoch 12/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1383 - accuracy: 0.9623 - val_loss: 0.1361 - val_accuracy: 0.9615\nEpoch 13/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1331 - accuracy: 0.9636 - val_loss: 0.1349 - val_accuracy: 0.9648\nEpoch 14/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1342 - accuracy: 0.9629 - val_loss: 0.1407 - val_accuracy: 0.9627\nEpoch 15/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1286 - accuracy: 0.9643 - val_loss: 0.1314 - val_accuracy: 0.9648\nEpoch 16/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1266 - accuracy: 0.9646 - val_loss: 0.1324 - val_accuracy: 0.9643\nEpoch 17/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1206 - accuracy: 0.9673 - val_loss: 0.1282 - val_accuracy: 0.9647\nEpoch 18/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1253 - accuracy: 0.9656 - val_loss: 0.1291 - val_accuracy: 0.9661\nEpoch 19/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1216 - accuracy: 0.9666 - val_loss: 0.1239 - val_accuracy: 0.9658\nEpoch 20/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1202 - accuracy: 0.9668 - val_loss: 0.1242 - val_accuracy: 0.9655\nEpoch 21/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1176 - accuracy: 0.9673 - val_loss: 0.1233 - val_accuracy: 0.9672\nEpoch 22/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1219 - accuracy: 0.9666 - val_loss: 0.1249 - val_accuracy: 0.9661\nEpoch 23/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1163 - accuracy: 0.9681 - val_loss: 0.1217 - val_accuracy: 0.9666\nEpoch 24/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1155 - accuracy: 0.9681 - val_loss: 0.1210 - val_accuracy: 0.9669\nEpoch 25/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1214 - accuracy: 0.9662 - val_loss: 0.1198 - val_accuracy: 0.9674\nEpoch 26/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1194 - accuracy: 0.9671 - val_loss: 0.1209 - val_accuracy: 0.9673\nEpoch 27/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1151 - accuracy: 0.9688 - val_loss: 0.1213 - val_accuracy: 0.9688\nEpoch 28/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1143 - accuracy: 0.9675 - val_loss: 0.1199 - val_accuracy: 0.9667\nEpoch 29/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1110 - accuracy: 0.9693 - val_loss: 0.1188 - val_accuracy: 0.9672\nEpoch 30/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1164 - accuracy: 0.9679 - val_loss: 0.1191 - val_accuracy: 0.9683\nEpoch 31/100\n1026/1026 [==============================] - 4s 4ms/step - loss: 0.1153 - accuracy: 0.9684 - val_loss: 0.1200 - val_accuracy: 0.9680\nEpoch 32/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1122 - accuracy: 0.9688 - val_loss: 0.1184 - val_accuracy: 0.9669\nEpoch 33/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1099 - accuracy: 0.9693 - val_loss: 0.1188 - val_accuracy: 0.9684\nEpoch 34/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1145 - accuracy: 0.9687 - val_loss: 0.1190 - val_accuracy: 0.9687\nEpoch 35/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1093 - accuracy: 0.9697 - val_loss: 0.1184 - val_accuracy: 0.9685\nEpoch 36/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1139 - accuracy: 0.9685 - val_loss: 0.1171 - val_accuracy: 0.9683\nEpoch 37/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1143 - accuracy: 0.9678 - val_loss: 0.1170 - val_accuracy: 0.9681\nEpoch 38/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1133 - accuracy: 0.9689 - val_loss: 0.1169 - val_accuracy: 0.9679\nEpoch 39/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1163 - accuracy: 0.9677 - val_loss: 0.1169 - val_accuracy: 0.9682\nEpoch 40/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1147 - accuracy: 0.9677 - val_loss: 0.1173 - val_accuracy: 0.9685\nEpoch 41/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1117 - accuracy: 0.9689 - val_loss: 0.1172 - val_accuracy: 0.9688\nEpoch 42/100\n1026/1026 [==============================] - 4s 3ms/step - loss: 0.1119 - accuracy: 0.9692 - val_loss: 0.1167 - val_accuracy: 0.9682\nEpoch 43/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1095 - accuracy: 0.9689 - val_loss: 0.1167 - val_accuracy: 0.9685\nEpoch 44/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1099 - accuracy: 0.9698 - val_loss: 0.1164 - val_accuracy: 0.9682\nEpoch 45/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1100 - accuracy: 0.9690 - val_loss: 0.1164 - val_accuracy: 0.9682\nEpoch 46/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1093 - accuracy: 0.9696 - val_loss: 0.1165 - val_accuracy: 0.9684\nEpoch 47/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1100 - accuracy: 0.9695 - val_loss: 0.1167 - val_accuracy: 0.9688\nEpoch 48/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1134 - accuracy: 0.9683 - val_loss: 0.1166 - val_accuracy: 0.9685\nEpoch 49/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1077 - accuracy: 0.9696 - val_loss: 0.1165 - val_accuracy: 0.9685\nEpoch 50/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1106 - accuracy: 0.9689 - val_loss: 0.1165 - val_accuracy: 0.9685\nEpoch 51/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1111 - accuracy: 0.9686 - val_loss: 0.1164 - val_accuracy: 0.9685\nEpoch 52/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1123 - accuracy: 0.9683 - val_loss: 0.1162 - val_accuracy: 0.9682\nEpoch 53/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1084 - accuracy: 0.9694 - val_loss: 0.1165 - val_accuracy: 0.9688\nEpoch 54/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1105 - accuracy: 0.9690 - val_loss: 0.1162 - val_accuracy: 0.9683\nEpoch 55/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1114 - accuracy: 0.9686 - val_loss: 0.1165 - val_accuracy: 0.9687\nEpoch 56/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1137 - accuracy: 0.9685 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 57/100\n","name":"stdout"},{"output_type":"stream","text":"1026/1026 [==============================] - 3s 3ms/step - loss: 0.1093 - accuracy: 0.9699 - val_loss: 0.1163 - val_accuracy: 0.9686\nEpoch 58/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1077 - accuracy: 0.9709 - val_loss: 0.1162 - val_accuracy: 0.9684\nEpoch 59/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1149 - accuracy: 0.9680 - val_loss: 0.1161 - val_accuracy: 0.9681\nEpoch 60/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1160 - accuracy: 0.9670 - val_loss: 0.1161 - val_accuracy: 0.9683\nEpoch 61/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1100 - accuracy: 0.9697 - val_loss: 0.1161 - val_accuracy: 0.9682\nEpoch 62/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1073 - accuracy: 0.9699 - val_loss: 0.1162 - val_accuracy: 0.9687\nEpoch 63/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1086 - accuracy: 0.9695 - val_loss: 0.1162 - val_accuracy: 0.9687\nEpoch 64/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1102 - accuracy: 0.9695 - val_loss: 0.1161 - val_accuracy: 0.9685\nEpoch 65/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1077 - accuracy: 0.9703 - val_loss: 0.1161 - val_accuracy: 0.9683\nEpoch 66/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1153 - accuracy: 0.9674 - val_loss: 0.1161 - val_accuracy: 0.9683\nEpoch 67/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1108 - accuracy: 0.9687 - val_loss: 0.1161 - val_accuracy: 0.9685\nEpoch 68/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1108 - accuracy: 0.9698 - val_loss: 0.1161 - val_accuracy: 0.9683\nEpoch 69/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1058 - accuracy: 0.9698 - val_loss: 0.1161 - val_accuracy: 0.9685\nEpoch 70/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1103 - accuracy: 0.9691 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 71/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1064 - accuracy: 0.9693 - val_loss: 0.1161 - val_accuracy: 0.9685\nEpoch 72/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1094 - accuracy: 0.9690 - val_loss: 0.1161 - val_accuracy: 0.9685\nEpoch 73/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1122 - accuracy: 0.9691 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 74/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1131 - accuracy: 0.9678 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 75/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1116 - accuracy: 0.9691 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 76/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1102 - accuracy: 0.9690 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 77/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1069 - accuracy: 0.9701 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 78/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1117 - accuracy: 0.9686 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 79/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1143 - accuracy: 0.9686 - val_loss: 0.1161 - val_accuracy: 0.9685\nEpoch 80/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1065 - accuracy: 0.9700 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 81/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1092 - accuracy: 0.9698 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 82/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1085 - accuracy: 0.9699 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 83/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1105 - accuracy: 0.9686 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 84/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1120 - accuracy: 0.9688 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 85/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1101 - accuracy: 0.9695 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 86/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1081 - accuracy: 0.9700 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 87/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1179 - accuracy: 0.9668 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 88/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1080 - accuracy: 0.9701 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 89/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1103 - accuracy: 0.9691 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 90/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1085 - accuracy: 0.9694 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 91/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1087 - accuracy: 0.9701 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 92/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1136 - accuracy: 0.9688 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 93/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1074 - accuracy: 0.9702 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 94/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1070 - accuracy: 0.9703 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 95/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1076 - accuracy: 0.9717 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 96/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1084 - accuracy: 0.9699 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 97/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1090 - accuracy: 0.9703 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 98/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1155 - accuracy: 0.9677 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 99/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1082 - accuracy: 0.9695 - val_loss: 0.1161 - val_accuracy: 0.9684\nEpoch 100/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1109 - accuracy: 0.9696 - val_loss: 0.1161 - val_accuracy: 0.9684\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rbflayer = RBFLayer(580,\n                    initializer=InitCentersKMeans(X_train),\n                    betas=2.0,\n                    input_shape=(29,))\n#-----Input layer------#\n\ninputs=tf.keras.layers.Input(shape=(29,))\n\n#-----RBF layer------#\n\nx1=rbflayer(inputs)\nx=Dense(5, activation='softmax', name='output')(x1)\n\noutputs=x\n\nmodel2=tf.keras.Model(inputs=inputs, outputs=outputs)\nmodel2.summary()","execution_count":23,"outputs":[{"output_type":"stream","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 29)]              0         \n_________________________________________________________________\nrbf_layer_1 (RBFLayer)       (None, 580)               17400     \n_________________________________________________________________\noutput (Dense)               (None, 5)                 2905      \n=================================================================\nTotal params: 20,305\nTrainable params: 20,305\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.compile(loss=tf.keras.losses.categorical_crossentropy,\n                  optimizer='Adam',\n                 metrics=['accuracy'])\n\nannealer = LearningRateScheduler(lambda x: 1e-2 * 0.9 ** x)\n\n\nhistory=model2.fit(X_train, y_train,\n              batch_size=64,\n              epochs=100,\n                  steps_per_epoch=len(X_train)//64,\n              validation_data=(X_test,y_test),\n                  callbacks=[annealer])","execution_count":24,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n1026/1026 [==============================] - 4s 3ms/step - loss: 0.3078 - accuracy: 0.9202 - val_loss: 0.1800 - val_accuracy: 0.9559\nEpoch 2/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1804 - accuracy: 0.9511 - val_loss: 0.1818 - val_accuracy: 0.9573\nEpoch 3/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1688 - accuracy: 0.9544 - val_loss: 0.1883 - val_accuracy: 0.9483\nEpoch 4/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1635 - accuracy: 0.9562 - val_loss: 0.1525 - val_accuracy: 0.9605\nEpoch 5/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1500 - accuracy: 0.9592 - val_loss: 0.1451 - val_accuracy: 0.9604\nEpoch 6/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1464 - accuracy: 0.9603 - val_loss: 0.1471 - val_accuracy: 0.9601\nEpoch 7/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1438 - accuracy: 0.9607 - val_loss: 0.1377 - val_accuracy: 0.9635\nEpoch 8/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1359 - accuracy: 0.9627 - val_loss: 0.1389 - val_accuracy: 0.9621\nEpoch 9/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1304 - accuracy: 0.9635 - val_loss: 0.1353 - val_accuracy: 0.9628\nEpoch 10/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1340 - accuracy: 0.9619 - val_loss: 0.1276 - val_accuracy: 0.9647\nEpoch 11/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1236 - accuracy: 0.9653 - val_loss: 0.1262 - val_accuracy: 0.9656\nEpoch 12/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1247 - accuracy: 0.9646 - val_loss: 0.1256 - val_accuracy: 0.9667\nEpoch 13/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1241 - accuracy: 0.9655 - val_loss: 0.1218 - val_accuracy: 0.9666\nEpoch 14/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1200 - accuracy: 0.9661 - val_loss: 0.1241 - val_accuracy: 0.9668\nEpoch 15/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1191 - accuracy: 0.9663 - val_loss: 0.1212 - val_accuracy: 0.9665\nEpoch 16/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1157 - accuracy: 0.9672 - val_loss: 0.1159 - val_accuracy: 0.9682\nEpoch 17/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1159 - accuracy: 0.9674 - val_loss: 0.1154 - val_accuracy: 0.9684\nEpoch 18/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1130 - accuracy: 0.9674 - val_loss: 0.1133 - val_accuracy: 0.9682\nEpoch 19/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1047 - accuracy: 0.9700 - val_loss: 0.1124 - val_accuracy: 0.9694\nEpoch 20/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1067 - accuracy: 0.9704 - val_loss: 0.1136 - val_accuracy: 0.9684\nEpoch 21/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1082 - accuracy: 0.9693 - val_loss: 0.1107 - val_accuracy: 0.9694\nEpoch 22/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1041 - accuracy: 0.9707 - val_loss: 0.1098 - val_accuracy: 0.9691\nEpoch 23/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1024 - accuracy: 0.9712 - val_loss: 0.1101 - val_accuracy: 0.9688\nEpoch 24/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1066 - accuracy: 0.9705 - val_loss: 0.1122 - val_accuracy: 0.9692\nEpoch 25/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1039 - accuracy: 0.9699 - val_loss: 0.1074 - val_accuracy: 0.9704\nEpoch 26/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1008 - accuracy: 0.9717 - val_loss: 0.1088 - val_accuracy: 0.9700\nEpoch 27/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1006 - accuracy: 0.9713 - val_loss: 0.1062 - val_accuracy: 0.9701\nEpoch 28/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1029 - accuracy: 0.9719 - val_loss: 0.1065 - val_accuracy: 0.9701\nEpoch 29/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.1022 - accuracy: 0.9707 - val_loss: 0.1089 - val_accuracy: 0.9685\nEpoch 30/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0996 - accuracy: 0.9706 - val_loss: 0.1067 - val_accuracy: 0.9700\nEpoch 31/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0973 - accuracy: 0.9720 - val_loss: 0.1061 - val_accuracy: 0.9695\nEpoch 32/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0981 - accuracy: 0.9713 - val_loss: 0.1056 - val_accuracy: 0.9706\nEpoch 33/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0977 - accuracy: 0.9715 - val_loss: 0.1064 - val_accuracy: 0.9707\nEpoch 34/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0950 - accuracy: 0.9733 - val_loss: 0.1048 - val_accuracy: 0.9704\nEpoch 35/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0951 - accuracy: 0.9725 - val_loss: 0.1058 - val_accuracy: 0.9705\nEpoch 36/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0970 - accuracy: 0.9714 - val_loss: 0.1049 - val_accuracy: 0.9704\nEpoch 37/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0956 - accuracy: 0.9725 - val_loss: 0.1045 - val_accuracy: 0.9709\nEpoch 38/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0935 - accuracy: 0.9736 - val_loss: 0.1047 - val_accuracy: 0.9708\nEpoch 39/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0958 - accuracy: 0.9734 - val_loss: 0.1043 - val_accuracy: 0.9709\nEpoch 40/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0917 - accuracy: 0.9742 - val_loss: 0.1041 - val_accuracy: 0.9710\nEpoch 41/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0993 - accuracy: 0.9714 - val_loss: 0.1040 - val_accuracy: 0.9708\nEpoch 42/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0937 - accuracy: 0.9737 - val_loss: 0.1040 - val_accuracy: 0.9708\nEpoch 43/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0980 - accuracy: 0.9729 - val_loss: 0.1046 - val_accuracy: 0.9703\nEpoch 44/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0943 - accuracy: 0.9735 - val_loss: 0.1041 - val_accuracy: 0.9708\nEpoch 45/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0959 - accuracy: 0.9723 - val_loss: 0.1037 - val_accuracy: 0.9710\nEpoch 46/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0942 - accuracy: 0.9730 - val_loss: 0.1041 - val_accuracy: 0.9708\nEpoch 47/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0918 - accuracy: 0.9738 - val_loss: 0.1037 - val_accuracy: 0.9708\nEpoch 48/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0941 - accuracy: 0.9734 - val_loss: 0.1033 - val_accuracy: 0.9709\nEpoch 49/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0936 - accuracy: 0.9733 - val_loss: 0.1034 - val_accuracy: 0.9708\nEpoch 50/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0955 - accuracy: 0.9731 - val_loss: 0.1034 - val_accuracy: 0.9709\nEpoch 51/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0949 - accuracy: 0.9735 - val_loss: 0.1038 - val_accuracy: 0.9710\nEpoch 52/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0940 - accuracy: 0.9729 - val_loss: 0.1033 - val_accuracy: 0.9710\nEpoch 53/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0936 - accuracy: 0.9732 - val_loss: 0.1033 - val_accuracy: 0.9710\nEpoch 54/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0943 - accuracy: 0.9734 - val_loss: 0.1033 - val_accuracy: 0.9708\nEpoch 55/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0956 - accuracy: 0.9717 - val_loss: 0.1033 - val_accuracy: 0.9709\nEpoch 56/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0960 - accuracy: 0.9722 - val_loss: 0.1033 - val_accuracy: 0.9710\nEpoch 57/100\n","name":"stdout"},{"output_type":"stream","text":"1026/1026 [==============================] - 3s 3ms/step - loss: 0.0951 - accuracy: 0.9727 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 58/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0948 - accuracy: 0.9726 - val_loss: 0.1033 - val_accuracy: 0.9709\nEpoch 59/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0913 - accuracy: 0.9736 - val_loss: 0.1033 - val_accuracy: 0.9709\nEpoch 60/100\n1026/1026 [==============================] - 4s 3ms/step - loss: 0.0957 - accuracy: 0.9732 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 61/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0907 - accuracy: 0.9740 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 62/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0930 - accuracy: 0.9738 - val_loss: 0.1031 - val_accuracy: 0.9708\nEpoch 63/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0880 - accuracy: 0.9752 - val_loss: 0.1032 - val_accuracy: 0.9708\nEpoch 64/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0915 - accuracy: 0.9736 - val_loss: 0.1032 - val_accuracy: 0.9709\nEpoch 65/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0923 - accuracy: 0.9739 - val_loss: 0.1031 - val_accuracy: 0.9708\nEpoch 66/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0926 - accuracy: 0.9728 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 67/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0913 - accuracy: 0.9739 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 68/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0941 - accuracy: 0.9731 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 69/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0969 - accuracy: 0.9729 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 70/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0936 - accuracy: 0.9734 - val_loss: 0.1030 - val_accuracy: 0.9709\nEpoch 71/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0906 - accuracy: 0.9741 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 72/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0937 - accuracy: 0.9733 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 73/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0936 - accuracy: 0.9729 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 74/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0922 - accuracy: 0.9742 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 75/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0925 - accuracy: 0.9736 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 76/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0927 - accuracy: 0.9724 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 77/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0914 - accuracy: 0.9743 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 78/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0910 - accuracy: 0.9738 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 79/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0926 - accuracy: 0.9735 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 80/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0947 - accuracy: 0.9722 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 81/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0918 - accuracy: 0.9744 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 82/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0994 - accuracy: 0.9720 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 83/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0885 - accuracy: 0.9748 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 84/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0926 - accuracy: 0.9735 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 85/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0902 - accuracy: 0.9749 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 86/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0914 - accuracy: 0.9741 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 87/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0956 - accuracy: 0.9727 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 88/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0939 - accuracy: 0.9728 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 89/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0923 - accuracy: 0.9730 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 90/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0919 - accuracy: 0.9733 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 91/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0926 - accuracy: 0.9737 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 92/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0952 - accuracy: 0.9718 - val_loss: 0.1031 - val_accuracy: 0.9709\nEpoch 93/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0962 - accuracy: 0.9726 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 94/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0948 - accuracy: 0.9725 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 95/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0889 - accuracy: 0.9741 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 96/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0941 - accuracy: 0.9740 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 97/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0942 - accuracy: 0.9731 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 98/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0954 - accuracy: 0.9726 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 99/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0923 - accuracy: 0.9737 - val_loss: 0.1031 - val_accuracy: 0.9710\nEpoch 100/100\n1026/1026 [==============================] - 3s 3ms/step - loss: 0.0908 - accuracy: 0.9742 - val_loss: 0.1031 - val_accuracy: 0.9710\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtest_feats = wpd(test_x)\nXtest_scaled = scaling(Xtest_feats)\nXtest_scaled = Xtest_scaled.reshape(-1,8,29)\n\nXtest_scaled_power_spectrum = wps(Xtest_scaled)\nX_tested = Xtest_scaled_power_spectrum","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tested_approx = X_tested[:,0,:]\ntest_y1 = tf.keras.utils.to_categorical(test_y, num_classes=5) \n\nypred1 = model1.predict(X_tested_approx)\n\nfor i in range(len(ypred1)):\n    ind=np.argmax(ypred1[i])\n    for j in range(5):\n        if j==ind:\n            ypred1[i][j]=1.\n        else:\n            ypred1[i][j]=0.\n            \n\n\ntarget_names = ['class 0', 'class 1', 'class 2',  'class 3',  'class 4']\nprint(classification_report(test_y1, ypred1, target_names=target_names, zero_division='warn'))","execution_count":21,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n     class 0       0.97      1.00      0.98     18118\n     class 1       0.93      0.56      0.70       556\n     class 2       0.94      0.87      0.90      1448\n     class 3       0.72      0.57      0.64       162\n     class 4       0.99      0.91      0.95      1608\n\n   micro avg       0.97      0.97      0.97     21892\n   macro avg       0.91      0.78      0.83     21892\nweighted avg       0.97      0.97      0.96     21892\n samples avg       0.97      0.97      0.97     21892\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.evaluate(X_tested_approx, test_y1)","execution_count":22,"outputs":[{"output_type":"stream","text":"685/685 [==============================] - 2s 2ms/step - loss: 0.1226 - accuracy: 0.9669\n","name":"stdout"},{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"[0.12256467342376709, 0.9669285416603088]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tested_approx = X_tested[:,0,:]\ntest_y2 = tf.keras.utils.to_categorical(test_y, num_classes=5) \n\nypred2 = model2.predict(X_tested_approx)\n\nfor i in range(len(ypred2)):\n    ind=np.argmax(ypred2[i])\n    for j in range(5):\n        if j==ind:\n            ypred2[i][j]=1.\n        else:\n            ypred2[i][j]=0.\n            \n\n\ntarget_names = ['class 0', 'class 1', 'class 2',  'class 3',  'class 4']\nprint(classification_report(test_y2, ypred2, target_names=target_names, zero_division='warn'))","execution_count":25,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n     class 0       0.97      1.00      0.98     18118\n     class 1       0.92      0.58      0.71       556\n     class 2       0.94      0.89      0.92      1448\n     class 3       0.73      0.56      0.63       162\n     class 4       0.99      0.92      0.95      1608\n\n   micro avg       0.97      0.97      0.97     21892\n   macro avg       0.91      0.79      0.84     21892\nweighted avg       0.97      0.97      0.97     21892\n samples avg       0.97      0.97      0.97     21892\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.evaluate(X_tested_approx, test_y2)","execution_count":26,"outputs":[{"output_type":"stream","text":"685/685 [==============================] - 1s 2ms/step - loss: 0.1112 - accuracy: 0.9693\n","name":"stdout"},{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"[0.11116894334554672, 0.9693495631217957]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}